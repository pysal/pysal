{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the handler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `spreg-handler` provides a unified interface to apply any specifed regression function in pysal to data, like a call to `lm` in `R`. \n",
    "\n",
    "This has 2 components. \n",
    "\n",
    "1. `registry.py`, which finds all of the valid model classes in `pysal.spreg`\n",
    "2. `handler.py`, which proves *one* function to estimate all of those classes.\n",
    "\n",
    "Thanks to the `registry`, `handler.Model` can serve as the single point of access for a `patsy`/`pandas` interface logic, as well as anything else that we might want to add to regression classes without forcing it through inheritance.\n",
    "\n",
    "First, let's set up and estimate some models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import handler as h\n",
    "import pysal as ps\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = gpd.read_file(ps.examples.get_path('columbus.json'))\n",
    "dbf = ps.open(ps.examples.get_path('columbus.dbf'))\n",
    "y = dbf.by_col_array(['HOVAL'])\n",
    "X = dbf.by_col_array(['INC', 'CRIME'])\n",
    "W = ps.open(ps.examples.get_path('columbus.gal')).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original = ps.spreg.OLS(y,X,W, name_x=['INC', 'CRIME'], name_y='HOVAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handler's default model is `OLS`. So, for a model of type `OLS`, no extra argument needs to be passed. However, for the sake of clarity, I'll pass the model specification argument, `mtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handled = h.Model(y,\n",
    "                  X,\n",
    "                  W,\n",
    "                  name_x=['INC', 'CRIME'], \n",
    "                  name_y='HOVAL', \n",
    "                  mtype='OLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n",
      "-----------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :       HOVAL                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           3\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          46\n",
      "R-squared           :      0.3495\n",
      "Adjusted R-squared  :      0.3212\n",
      "Sum squared residual:   10647.015                F-statistic           :     12.3582\n",
      "Sigma-square        :     231.457                Prob(F-statistic)     :   5.064e-05\n",
      "S.E. of regression  :      15.214                Log likelihood        :    -201.368\n",
      "Sigma-square ML     :     217.286                Akaike info criterion :     408.735\n",
      "S.E of regression ML:     14.7406                Schwarz criterion     :     414.411\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     t-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      46.4281827      13.1917570       3.5194844       0.0009867\n",
      "               CRIME      -0.4848885       0.1826729      -2.6544086       0.0108745\n",
      "                 INC       0.6289840       0.5359104       1.1736736       0.2465669\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "REGRESSION DIAGNOSTICS\n",
      "MULTICOLLINEARITY CONDITION NUMBER           12.538\n",
      "\n",
      "TEST ON NORMALITY OF ERRORS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Jarque-Bera                       2          39.706           0.0000\n",
      "\n",
      "DIAGNOSTICS FOR HETEROSKEDASTICITY\n",
      "RANDOM COEFFICIENTS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Breusch-Pagan test                2           5.767           0.0559\n",
      "Koenker-Bassett test              2           2.270           0.3214\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(original.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n",
      "-----------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :       HOVAL                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           3\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          46\n",
      "R-squared           :      0.3495\n",
      "Adjusted R-squared  :      0.3212\n",
      "Sum squared residual:   10647.015                F-statistic           :     12.3582\n",
      "Sigma-square        :     231.457                Prob(F-statistic)     :   5.064e-05\n",
      "S.E. of regression  :      15.214                Log likelihood        :    -201.368\n",
      "Sigma-square ML     :     217.286                Akaike info criterion :     408.735\n",
      "S.E of regression ML:     14.7406                Schwarz criterion     :     414.411\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     t-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      46.4281827      13.1917570       3.5194844       0.0009867\n",
      "               CRIME      -0.4848885       0.1826729      -2.6544086       0.0108745\n",
      "                 INC       0.6289840       0.5359104       1.1736736       0.2465669\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "REGRESSION DIAGNOSTICS\n",
      "MULTICOLLINEARITY CONDITION NUMBER           12.538\n",
      "\n",
      "TEST ON NORMALITY OF ERRORS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Jarque-Bera                       2          39.706           0.0000\n",
      "\n",
      "DIAGNOSTICS FOR HETEROSKEDASTICITY\n",
      "RANDOM COEFFICIENTS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Breusch-Pagan test                2           5.767           0.0559\n",
      "Koenker-Bassett test              2           2.270           0.3214\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(handled.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The long and short of it is that `Model` classes pass estimation to the function specified in `mtype`, and then contain the results in a reasonable way. \n",
    "\n",
    "In fact, the \"real\" `PySAL` model class sits under `handled._called`, so, at worst, we can just reference aspects of `handled` down to `_called`. I currently do this by iterating through `dir(handled._called)` and using `eval` to flatten all of `_called`'s attributes into `handled` at initialization. \n",
    "\n",
    "But, eventually, I am think about adding plotting, visual diagnostics, out of sample prediction, or other stuff to this wrapper. So, I will probably not duplicate the access points for intermediate computations, like `X'X`, `e`, or `TSLS`'s arcane-sounding `zthhthi`.\n",
    "\n",
    "I'd like to clean up this `Model` interface so that only X, Y, residuals, and some statistics are directly exposed. \n",
    "\n",
    "Keep in mind, since [assignment **never** copies data](https://youtu.be/_AEJHKGk9ns?t=296), and the original model sits in `handled._called`, this isn't actually a *loss* of information, just a *hiding*, which is a standard OOP principle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isn't this wastefully storing multiple copies of data in memory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. Let's see where everything lives using the python built-in `id` function. \n",
    "\n",
    "Recall that the original model is stuffed into `Model._called`. So, if anything in there has a different memory address from what's being displayed by `Model`, the data is duplicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__is in two different addresses.\n",
      "\t Outer is at 0x7f11fbb2dcd0\n",
      "\t Inner is at 0x7f11fbb92820\n"
     ]
    }
   ],
   "source": [
    "for atname in dir(handled._called):\n",
    "    attr = eval(\"handled._called.{}\".format(atname))\n",
    "    composed_id = hex(id(attr))\n",
    "    outattr = eval(\"handled.{}\".format(atname))\n",
    "    outer_id = hex(id(outattr))\n",
    "    if composed_id != outer_id:\n",
    "        print(atname + \"is in two different addresses.\")\n",
    "        print(\"\\t Outer is at \" + outer_id +\"\\n\\t Inner is at \" + composed_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the `__init__` function exposed by `Model` is different from `Model._called`, which makes sense, since an `__init__` function can't write over itself. \n",
    "\n",
    "If we wanted to access `Model._called.__init__`, it's still there. This means we could implement some \"refit\" method, `Model.refit(y=Model.y, X=Model.X, ...)` which could use `Model._called.__init__` to revise estimates in `Model` in place or returning a new model.\n",
    "\n",
    "I don't know why we might want to do this, but it's kinda neat :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does this buy us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless, all the stuff the wrapping `Model` class is parsed *around* the underlying PySAL classes. That is, the wrapper would only inject commands into the API. At minimum, it *is exactly* the underlying class. \n",
    "\n",
    "This is because it dispatches the arguments to the specified model type without knowing any special information about the function call.  \n",
    "\n",
    "This means we can do some pretty cool things, while keeping the actual wrapper at ~40 LoC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljw/.local/lib/python2.7/site-packages/scipy/optimize/_minimize.py:593: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  \"defaulting to absolute tolerance.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "ML = ps.spreg.ML_Lag(y,X,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handled_ML = h.Model(y,X,W,mtype='ML_Lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL LAG (METHOD = FULL)\n",
      "-----------------------------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           4\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          45\n",
      "Pseudo R-squared    :      0.3639\n",
      "Spatial Pseudo R-squared:  0.3384\n",
      "Sigma-square ML     :     212.490                Log likelihood        :    -200.903\n",
      "S.E of regression   :      14.577                Akaike info criterion :     409.807\n",
      "                                                 Schwarz criterion     :     417.374\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      44.1882822      12.9020363       3.4249076       0.0006150\n",
      "           W_dep_var       0.0259466       0.0262601       0.9880621       0.3231223\n",
      "               var_1       0.5453705       0.5209327       1.0469117       0.2951403\n",
      "               var_2      -0.5186558       0.1768050      -2.9334902       0.0033517\n",
      "------------------------------------------------------------------------------------\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(ML.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL LAG (METHOD = FULL)\n",
      "-----------------------------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           4\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          45\n",
      "Pseudo R-squared    :      0.3639\n",
      "Spatial Pseudo R-squared:  0.3384\n",
      "Sigma-square ML     :     212.490                Log likelihood        :    -200.903\n",
      "S.E of regression   :      14.577                Akaike info criterion :     409.807\n",
      "                                                 Schwarz criterion     :     417.374\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      44.1882822      12.9020363       3.4249076       0.0006150\n",
      "           W_dep_var       0.0259466       0.0262601       0.9880621       0.3231223\n",
      "               var_1       0.5453705       0.5209327       1.0469117       0.2951403\n",
      "               var_2      -0.5186558       0.1768050      -2.9334902       0.0033517\n",
      "------------------------------------------------------------------------------------\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(handled_ML.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercepting formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is pretty neat, but gives us nothing above using *one* function to dispatch models. That's cool and R-like, but it's not necessarly better. Where it does add functionality is in its ability to intercept model formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handled_eq = h.Model(\"HOVAL ~ INC + CRIME\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n",
      "-----------------------------------------\n",
      "Data set            :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     38.4362                Number of Variables   :           3\n",
      "S.D. dependent var  :     18.4661                Degrees of Freedom    :          46\n",
      "R-squared           :      0.3495\n",
      "Adjusted R-squared  :      0.3212\n",
      "Sum squared residual:   10647.015                F-statistic           :     12.3582\n",
      "Sigma-square        :     231.457                Prob(F-statistic)     :   5.064e-05\n",
      "S.E. of regression  :      15.214                Log likelihood        :    -201.368\n",
      "Sigma-square ML     :     217.286                Akaike info criterion :     408.735\n",
      "S.E of regression ML:     14.7406                Schwarz criterion     :     414.411\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     t-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      46.4281827      13.1917570       3.5194844       0.0009867\n",
      "               var_1       0.6289840       0.5359104       1.1736736       0.2465669\n",
      "               var_2      -0.4848885       0.1826729      -2.6544086       0.0108745\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "REGRESSION DIAGNOSTICS\n",
      "MULTICOLLINEARITY CONDITION NUMBER           12.538\n",
      "\n",
      "TEST ON NORMALITY OF ERRORS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Jarque-Bera                       2          39.706           0.0000\n",
      "\n",
      "DIAGNOSTICS FOR HETEROSKEDASTICITY\n",
      "RANDOM COEFFICIENTS\n",
      "TEST                             DF        VALUE           PROB\n",
      "Breusch-Pagan test                2           5.767           0.0559\n",
      "Koenker-Bassett test              2           2.270           0.3214\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(handled_eq.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means `HOVAL`, `CRIME`, and `INC` all get drawn out of the dataframe using patsy and pushed into arrays. This works for any class, since we're just turning the equations into their consituent arrays. \n",
    "\n",
    "Where there is a possible bikeshedding point is over the syntax for TSLS-type models. Right now, I have it specified with (what I think is) a clear synatx reflecting the simultanous equations approach: \n",
    "\n",
    "`y ~ x1 + x2 || yend ~ xend1 + xend2`\n",
    "\n",
    "implies an equation where your exogenous relationship is `y ~ x1 + x2` and your endogenous relationship is `yend ~ xend1 + xend2`. \n",
    "\n",
    "For any simultaneous equation-type model, I would suggest using double pipe as the separator. Under the hood, I'm just using `string.split('||')`, since patsy doesn't use the double pipe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = dbf.by_col_array(['CRIME'])\n",
    "X = dbf.by_col_array(['INC'])\n",
    "yend = dbf.by_col_array(['HOVAL'])\n",
    "q = dbf.by_col_array(['DISCBD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsls = ps.spreg.TSLS(y,X,yend,q,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handledtsls = h.Model(y,X,yend,q,W,mtype='TSLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handledtsls_eq = h.Model(\"CRIME ~ INC || HOVAL ~ DISCBD\", W, data=df, mtype='TSLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: TWO STAGE LEAST SQUARES\n",
      "------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     35.1288                Number of Variables   :           3\n",
      "S.D. dependent var  :     16.7321                Degrees of Freedom    :          46\n",
      "Pseudo R-squared    :      0.2794\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      88.4657958      15.1346096       5.8452645       0.0000000\n",
      "        endogenous_1      -1.5821659       0.7931892      -1.9946891       0.0460768\n",
      "               var_1       0.5200379       1.4146781       0.3676016       0.7131703\n",
      "------------------------------------------------------------------------------------\n",
      "Instrumented: endogenous_1\n",
      "Instruments: instrument_1\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(tsls.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: TWO STAGE LEAST SQUARES\n",
      "------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     35.1288                Number of Variables   :           3\n",
      "S.D. dependent var  :     16.7321                Degrees of Freedom    :          46\n",
      "Pseudo R-squared    :      0.2794\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      88.4657958      15.1346096       5.8452645       0.0000000\n",
      "        endogenous_1      -1.5821659       0.7931892      -1.9946891       0.0460768\n",
      "               var_1       0.5200379       1.4146781       0.3676016       0.7131703\n",
      "------------------------------------------------------------------------------------\n",
      "Instrumented: endogenous_1\n",
      "Instruments: instrument_1\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(handledtsls.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: TWO STAGE LEAST SQUARES\n",
      "------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     35.1288                Number of Variables   :           3\n",
      "S.D. dependent var  :     16.7321                Degrees of Freedom    :          46\n",
      "Pseudo R-squared    :      0.2794\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      88.4657958      15.1346096       5.8452645       0.0000000\n",
      "        endogenous_1      -1.5821659       0.7931892      -1.9946891       0.0460768\n",
      "               var_1       0.5200379       1.4146781       0.3676016       0.7131703\n",
      "------------------------------------------------------------------------------------\n",
      "Instrumented: endogenous_1\n",
      "Instruments: instrument_1\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(handledtsls_eq.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would also enable adding plotting capabilities to spatial regression models, like the standard four-plot output from plotting an `lm` in `R`, but wouldn't have to be hacked into each and every model class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper is neat, but could lead us down a weird road.\n",
    "\n",
    "Right now, I clean up the mandatory arguments tuple `*args` such that only the arguments that match the type signature needed by PySAL get passed. This is to prevent runtime errors.\n",
    "\n",
    "To explain, let some function be defined using the default Python argument expansion (a.k.a. splatting) operator, `*`:\n",
    "\n",
    "        def foo(*args, message='Hello'):\n",
    "            for arg in args:\n",
    "                print(message + args)\n",
    "        \n",
    "        >>> foo(\"world!\", \"users!\")\n",
    "        Hello world!\n",
    "        Hello users!\n",
    "        \n",
    "Cool. Now, let's say we want to print our message right before we execute some function, `bar`. `bar` is a model class with a well-defined API. It requires two positional arguments of type `ndarray`, `y` and `X`, can accept an arbitrary number of keyword arguments, and returns `True` if a model is fit correctly. \n",
    "\n",
    "For the sake of argument (no pun intended), let's say that `foo` only needs the strings passed as positional arguments. Depending on your python version, we can wrap `bar` with `foo` this way:\n",
    "\n",
    "        def foo(*args, message='Hello', **kwargs):\n",
    "            strargs = [arg for arg in args if isinstance(args, str)]\n",
    "            barargs = [arg for arg in args if arg not in strargs]\n",
    "            for arg in args:\n",
    "                print(message + arg)\n",
    "            return bar(*args, **kwargs)\n",
    "            \n",
    "If we do this, arbitrary arguments could get passed to `foo` that, if `bar` isn't expecting them, will cause a `TypeError`. \n",
    "\n",
    "        >>> foo(\"world!\", \"users!\", 12313, y, X)\n",
    "        Hello world!\n",
    "        Hello users!\n",
    "        -------------------------------------------\n",
    "        TypeError\n",
    "        return bar(*args, **kwargs)\n",
    "        \n",
    "        TypeError: bar() takes exactly 2 arguments (3 given)\n",
    " \n",
    "Some libraries (*ahem* Matplotlib) get around this by making almost every function take arbitrary arguments, and each function just peels off of `args` and `kwargs` what it needs. \n",
    "\n",
    "This isn't us, though. I would suggest that the standard be that we use input types or ordering of arguments to define how to wrap the underlying functions. This means that, if we know `bar` accepts a `y` and an `X` of type `ndarray` in that order, we pop off of a stack of arguments with the current scope's arguments at the top of the stack.\n",
    "\n",
    "Here, since we know that we're wrapping one function with two arguments, its arguments are at the bottom of the stack. \n",
    "\n",
    "        def foo(*args, message=\"Hello\", **kwargs):\n",
    "            args.pop() = X\n",
    "            args.pop() = y\n",
    "            for arg in args:\n",
    "                print(message + arg)\n",
    "            return bar(y, X, **kwargs)\n",
    "       \n",
    "        >>> foo(\"world!\", \"users!\", y, X)\n",
    "        Hello world!\n",
    "        Hello users!\n",
    "        True #model fit successfully\n",
    "        \n",
    "Of course, we could also get even more abstract. We could construct a list of arguments for the wrapped function based on the *types* expected by that function. If we can identify or construct subsequences of *args* that match the function we're wrapping, we're good to go. \n",
    "\n",
    "However, these strategies have the strange side effect that, if extra arguments are passed, no error is raised. This could be desirable, but may not be if the user expects the arguments to **do** something. \n",
    "\n",
    "The call with ignored arguments looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handledtsls_ignored = h.Model(\"CRIME ~ INC || HOVAL ~ DISCBD\",\n",
    "                              True, #gets ignored\n",
    "                              W, \n",
    "                              42, #gets ignored too\n",
    "                              data=df, \n",
    "                              mtype='GM_Lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----------\n",
      "SUMMARY OF OUTPUT: SPATIAL TWO STAGE LEAST SQUARES\n",
      "--------------------------------------------------\n",
      "Data set            :     unknown\n",
      "Weights matrix      :     unknown\n",
      "Dependent Variable  :     dep_var                Number of Observations:          49\n",
      "Mean dependent var  :     35.1288                Number of Variables   :           4\n",
      "S.D. dependent var  :     16.7321                Degrees of Freedom    :          45\n",
      "Pseudo R-squared    :      0.2377\n",
      "Spatial Pseudo R-squared:  0.2477\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "            Variable     Coefficient       Std.Error     z-Statistic     Probability\n",
      "------------------------------------------------------------------------------------\n",
      "            CONSTANT      96.5182979      52.5305917       1.8373731       0.0661548\n",
      "           W_dep_var      -0.0148182       0.0857203      -0.1728667       0.8627562\n",
      "        endogenous_1      -1.8097627       1.7652028      -1.0252436       0.3052483\n",
      "               var_1       0.7561942       2.3367036       0.3236158       0.7462289\n",
      "------------------------------------------------------------------------------------\n",
      "Instrumented: W_dep_var, endogenous_1\n",
      "Instruments: W_instrument_1, W_var_1, instrument_1\n",
      "================================ END OF REPORT =====================================\n"
     ]
    }
   ],
   "source": [
    "print(handledtsls_ignored.summary) #woah! no error or notice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those other positional arguments get ignored in the equation framework. \n",
    "\n",
    "Practically, this means you couldn't provide some variables in equations and some in vectors... you'd have to either have equations or vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
